Music recommendation based on adaptive feature and user grouping 
Introduction
WIDESPREAD use of mp3 players and cell-phones and availability of music on these devices according to user demands increased the need for more accurate Music Information Retrieval (MIR) Systems. Music recommendation is one of the subtasks of MIR Systems and it involves finding music that suits a personal taste [1]. Audioscrobbler, iRate, MusicStrands, and inDiscover are some of the music recommendation systems today [2]. Usually music recommendation systems follow a collaborative filtering or a content-based approach. Collaborative filtering is the approach used in Amazon [3], a new item is rated by some users and the item is recommended to other users based on the rating of the previous users [4], [5]. The disadvantage of the collaborative approach is that when a new item arrives, it has to be rated by someone in order to be used for the other users. In the content-based approach, based on some form of distance between the items already rated by the user and a new item, the item is recommended or not [2], [6], [7], [8]. In order to compute similarities between music pieces different approaches have been suggested. In this paper, we use low level musical features extracted from the audio signals. In the past, two studies [9], [10] have also considered collaborative and content based methods for music recommendation. In [9] a Bayesian network is used to include both rating and content data for the recommendation and the hybrid approach is shown to produce better recommendations than using collaborative or content-based approach alone. [10] also use a hybrid approach, where they evaluate CB (Content Based), COL (Collaborative Filtering) and STA (Statistical) methods and their combinations. We base some of our work on that of [10] and give more information about this work below.

In our hybris music recommendation system, apart from previous studies, we use the observation that a person may base his/her choice for a song on certain aspects of the song, such as its rhythm or melody. We consider audio features of a song according to four different sets of feratures (MFCC, MPITCH, BEAT, STFT) obtained using the Marsyas software [opihi.cs.uvic.ca/marsyas] of Tzanetakis [14]. We use features that can be used to cluster the songs a user has listened to as compact as possible. As a measure of compactness, we use an entropy criterion. When we recommend a certain number of songs, M, to the user at a certain time, we recommend a certain percentage of songs based on the content of the songs the user has listened to so far and the song and the user clustering in which the user is. We recommend the remaining songs based on the popular songs at the time of the recommendation and the user's past history. Unlike [10], instead of system-wide weights, we use adaptive weights for each user based on the user's listening history. In addition to the algorithms introduced in [17], in this paper we introduce the user group learning based algorithm.

The rest of the paper is organized as follows. In Sections 2 and 3, we introduce the data set we used and the features we extracted from songs so that we can measure similarities between them. Section 4 contains descriptions of our recommendation systems and the recommendation success we obtained using each of them. Section 5 concludes the paper.